{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GW2 Flipping Optimizer - Fill Probability Model\n",
        "\n",
        "This notebook builds Weibull models for sell fill times per item."
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from lifelines import WeibullFitter\n",
        "\n",
        "# If running locally, adjust paths as needed\n",
        "# If running in Colab, you'll need to upload your data folder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load Transaction History"
      ],
      "metadata": {
        "id": "load_data"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sell history (this is what we need for sell fill probabilities)\n",
        "sell_data_path = 'data/sell_orders/sell_history_2024-12-15.csv'  # adjust date as needed\n",
        "sells = pd.read_csv(sell_data_path)\n",
        "\n",
        "print(f\"Loaded {len(sells)} sell transactions\")\n",
        "print(f\"Unique items: {sells['item_id'].nunique()}\")\n",
        "sells.head()"
      ],
      "metadata": {
        "id": "load_sells"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "eda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Most traded items by quantity\n",
        "sells.groupby('item_name').agg({\n",
        "    'quantity': 'sum',\n",
        "    'time_to_fill_hours': ['mean', 'median', 'std']\n",
        "}).sort_values(('quantity', 'sum'), ascending=False).head(20)"
      ],
      "metadata": {
        "id": "eda_groupby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of fill times\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sells['time_to_fill_hours'], bins=50, edgecolor='black')\n",
        "plt.xlabel('Time to Fill (hours)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sell Order Fill Times')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Median fill time: {sells['time_to_fill_hours'].median():.2f} hours\")\n",
        "print(f\"Mean fill time: {sells['time_to_fill_hours'].mean():.2f} hours\")"
      ],
      "metadata": {
        "id": "eda_dist"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Weibull Distribution Theory\n",
        "\n",
        "The Weibull distribution is commonly used in survival analysis. For our use case:\n",
        "- **Event**: Item sells (\"failure\" in survival analysis terms)\n",
        "- **Duration**: Time from listing to sale\n",
        "- **Censoring**: Items not yet sold (we'll handle this later with more data)\n",
        "\n",
        "The Weibull PDF:\n",
        "$$f(t) = \\frac{\\rho}{\\lambda} \\left( \\frac{t}{\\lambda} \\right)^{\\rho-1} e^{-\\left( \\frac{t}{\\lambda} \\right)^\\rho}$$\n",
        "\n",
        "The Weibull CDF (what we need for fill probability):\n",
        "$$F(t) = 1 - e^{-\\left( \\frac{t}{\\lambda} \\right)^\\rho}$$\n",
        "\n",
        "Where:\n",
        "- $\\lambda$ (lambda) is the **scale parameter** - roughly the characteristic lifetime\n",
        "- $\\rho$ (rho) is the **shape parameter** - determines if failure rate increases/decreases over time\n",
        "  - $\\rho < 1$: Items more likely to sell early (fast movers)\n",
        "  - $\\rho = 1$: Constant sell rate (exponential distribution)\n",
        "  - $\\rho > 1$: Items more likely to sell later (slow movers)\n",
        "\n",
        "For our optimizer, we use $F(t)$ to calculate: **P(item sells within t hours)**"
      ],
      "metadata": {
        "id": "theory"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fit Weibull Models Per Item"
      ],
      "metadata": {
        "id": "fit_models"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_item_models(df, min_observations=3):\n",
        "    \"\"\"\n",
        "    Fit Weibull distribution for each item with sufficient data.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with columns [item_id, item_name, time_to_fill_hours]\n",
        "        min_observations: Minimum number of sales required to fit a model\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary mapping item_id -> model parameters\n",
        "    \"\"\"\n",
        "    item_distributions = {}\n",
        "    \n",
        "    # Group by item_id (not item_name to avoid duplicate issues)\n",
        "    for item_id, group in df.groupby('item_id'):\n",
        "        if len(group) < min_observations:\n",
        "            continue\n",
        "        \n",
        "        item_name = group['item_name'].iloc[0]\n",
        "        durations = group['time_to_fill_hours'].dropna()\n",
        "        \n",
        "        # Fit Weibull\n",
        "        wf = WeibullFitter()\n",
        "        wf.fit(durations)\n",
        "        \n",
        "        item_distributions[int(item_id)] = {\n",
        "            'item_name': item_name,\n",
        "            'lambda_': float(wf.lambda_),  # scale parameter\n",
        "            'rho_': float(wf.rho_),        # shape parameter\n",
        "            'n_observations': len(durations),\n",
        "            'median_fill_hours': float(durations.median()),\n",
        "            'mean_fill_hours': float(durations.mean()),\n",
        "            'std_fill_hours': float(durations.std())\n",
        "        }\n",
        "    \n",
        "    return item_distributions"
      ],
      "metadata": {
        "id": "fit_function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit models\n",
        "print(\"Fitting Weibull models per item...\")\n",
        "models = fit_item_models(sells, min_observations=3)\n",
        "print(f\"Fitted models for {len(models)} items\")\n",
        "\n",
        "# Save to JSON for later use\n",
        "os.makedirs('data', exist_ok=True)\n",
        "with open('data/item_fill_models.json', 'w') as f:\n",
        "    json.dump(models, f, indent=2)\n",
        "print(\"Models saved to data/item_fill_models.json\")"
      ],
      "metadata": {
        "id": "fit_execute"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Calculate Fill Probabilities"
      ],
      "metadata": {
        "id": "calc_probs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fill_probability(lambda_, rho_, time_horizon_days):\n",
        "    \"\"\"\n",
        "    Calculate P(item fills within time_horizon_days) using Weibull CDF.\n",
        "    \n",
        "    F(t) = 1 - exp(-(t/lambda)^rho)\n",
        "    \n",
        "    Args:\n",
        "        lambda_: Scale parameter from Weibull fit\n",
        "        rho_: Shape parameter from Weibull fit\n",
        "        time_horizon_days: Time horizon in DAYS (converted to hours internally)\n",
        "    \n",
        "    Returns:\n",
        "        Probability between 0 and 1\n",
        "    \"\"\"\n",
        "    time_horizon_hours = time_horizon_days * 24\n",
        "    return 1 - np.exp(-((time_horizon_hours / lambda_) ** rho_))"
      ],
      "metadata": {
        "id": "calc_prob_function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: What's the probability each item fills within different time horizons?\n",
        "time_horizons = [1, 3, 7]  # days\n",
        "\n",
        "print(\"\\nFill probabilities for top 10 items:\\n\")\n",
        "print(f\"{'Item':<30} {'N':<5} {'Rho':<6} {'1d':<8} {'3d':<8} {'7d':<8}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for item_id, model in list(models.items())[:10]:\n",
        "    probs = [calculate_fill_probability(model['lambda_'], model['rho_'], days) \n",
        "             for days in time_horizons]\n",
        "    \n",
        "    print(f\"{model['item_name'][:30]:<30} \"\n",
        "          f\"{model['n_observations']:<5} \"\n",
        "          f\"{model['rho_']:<6.2f} \"\n",
        "          f\"{probs[0]:<8.1%} \"\n",
        "          f\"{probs[1]:<8.1%} \"\n",
        "          f\"{probs[2]:<8.1%}\")"
      ],
      "metadata": {
        "id": "calc_prob_demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Prepare Data for Optimizer\n",
        "\n",
        "Now we need to combine:\n",
        "1. Fill probability models (what we just built)\n",
        "2. Current market prices (from GW2 API)\n",
        "3. Calculate margins and filter candidates"
      ],
      "metadata": {
        "id": "optimizer_prep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fetch current market prices from GW2 API\n",
        "# For now, using dummy data structure to show the concept\n",
        "\n",
        "def prepare_optimizer_input(models, market_data, \n",
        "                            min_margin=0.05, \n",
        "                            min_fill_prob=0.9, \n",
        "                            time_horizon_days=7):\n",
        "    \"\"\"\n",
        "    Prepare candidate items for LP optimizer.\n",
        "    \n",
        "    Args:\n",
        "        models: Dictionary of item_id -> Weibull parameters\n",
        "        market_data: Dictionary of item_id -> {buy_price, sell_price}\n",
        "        min_margin: Minimum profit margin (e.g., 0.05 = 5%)\n",
        "        min_fill_prob: Minimum fill probability (e.g., 0.9 = 90%)\n",
        "        time_horizon_days: Time horizon in DAYS\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with columns: item_id, item_name, buy_price, sell_price,\n",
        "                                margin_pct, fill_probability, expected_profit_per_item\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    \n",
        "    for item_id, model in models.items():\n",
        "        # Get market data for this item\n",
        "        if item_id not in market_data:\n",
        "            continue\n",
        "        \n",
        "        buy_price = market_data[item_id]['buy_price']   # copper\n",
        "        sell_price = market_data[item_id]['sell_price'] # copper\n",
        "        \n",
        "        # Calculate metrics\n",
        "        margin = (sell_price - buy_price) / buy_price\n",
        "        fill_prob = calculate_fill_probability(\n",
        "            model['lambda_'], \n",
        "            model['rho_'], \n",
        "            time_horizon_days\n",
        "        )\n",
        "        \n",
        "        # Apply filters\n",
        "        if margin < min_margin:\n",
        "            continue\n",
        "        if fill_prob < min_fill_prob:\n",
        "            continue\n",
        "        \n",
        "        # Calculate expected profit (accounting for fill probability)\n",
        "        expected_profit = (sell_price - buy_price) * fill_prob\n",
        "        \n",
        "        candidates.append({\n",
        "            'item_id': item_id,\n",
        "            'item_name': model['item_name'],\n",
        "            'buy_price': buy_price,\n",
        "            'sell_price': sell_price,\n",
        "            'margin_pct': margin * 100,\n",
        "            'fill_probability': fill_prob,\n",
        "            'expected_profit_per_item': expected_profit,\n",
        "            'lambda_': model['lambda_'],\n",
        "            'rho_': model['rho_']\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(candidates).sort_values('expected_profit_per_item', ascending=False)"
      ],
      "metadata": {
        "id": "optimizer_prep_function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with dummy market data\n",
        "# TODO: Replace with actual API call to /v2/commerce/prices\n",
        "\n",
        "dummy_market_data = {}\n",
        "for item_id in list(models.keys())[:5]:\n",
        "    dummy_market_data[item_id] = {\n",
        "        'buy_price': 1000,   # dummy\n",
        "        'sell_price': 1150   # dummy\n",
        "    }\n",
        "\n",
        "# Prepare candidates\n",
        "candidates = prepare_optimizer_input(\n",
        "    models=models,\n",
        "    market_data=dummy_market_data,\n",
        "    min_margin=0.05,\n",
        "    min_fill_prob=0.9,\n",
        "    time_horizon_days=7\n",
        ")\n",
        "\n",
        "print(f\"\\nFound {len(candidates)} candidate items for optimization\")\n",
        "print(\"\\nTop candidates:\")\n",
        "candidates.head(10)"
      ],
      "metadata": {
        "id": "optimizer_prep_demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "- [ ] Fetch real market prices from GW2 API\n",
        "- [ ] Build LP optimizer that takes these candidates and budget constraints\n",
        "- [ ] Account for current positions (items already bought/listed)\n",
        "- [ ] Build buy fill probability models (separate from sell fills)\n",
        "- [ ] Integrate into Flask GUI"
      ],
      "metadata": {
        "id": "next_steps"
      }
    }
  ]
}
